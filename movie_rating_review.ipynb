{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6adadfa5-2205-4135-a7d4-d7dace0c06a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6adadfa5-2205-4135-a7d4-d7dace0c06a8",
        "outputId": "ee274d7d-3a11-4cc3-b5e1-e921ff1c69ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 357ms/step - loss: 77830.7344 - mae: 159.2390 - val_loss: 22.2068 - val_mae: 3.7384\n",
            "Epoch 2/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 354ms/step - loss: 187.1405 - mae: 9.1117 - val_loss: 12.3142 - val_mae: 2.8704\n",
            "Epoch 3/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 352ms/step - loss: 51.2161 - mae: 5.0837 - val_loss: 7.8794 - val_mae: 2.3924\n",
            "Epoch 4/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 359ms/step - loss: 24.1498 - mae: 3.8439 - val_loss: 7.2983 - val_mae: 2.3326\n",
            "Epoch 5/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 352ms/step - loss: 18.6307 - mae: 3.5172 - val_loss: 6.1793 - val_mae: 2.1513\n",
            "Epoch 6/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 352ms/step - loss: 17.7488 - mae: 3.4756 - val_loss: 6.7803 - val_mae: 2.2832\n",
            "Epoch 7/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 341ms/step - loss: 16.3068 - mae: 3.3387 - val_loss: 5.3296 - val_mae: 2.0086\n",
            "Epoch 8/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 361ms/step - loss: 15.7004 - mae: 3.2827 - val_loss: 5.6786 - val_mae: 2.0952\n",
            "Epoch 9/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 354ms/step - loss: 14.9430 - mae: 3.2253 - val_loss: 5.0202 - val_mae: 1.9649\n",
            "Epoch 10/10\n",
            "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 351ms/step - loss: 14.4383 - mae: 3.1438 - val_loss: 4.4529 - val_mae: 1.8234\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - loss: 4.7183 - mae: 1.8614\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.5301337242126465, 1.8230369091033936]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate, Dropout, LSTM, TextVectorization\n",
        "\n",
        "df=pd.read_csv(\"top10K-TMDB-movies.csv\")\n",
        "\n",
        "#from sklearn.model_selection import train_test_split\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(df,)\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df[\"genre\"] = label_encoder.fit_transform(df['genre'])\n",
        "df['original_language']= label_encoder.fit_transform(df['original_language'])\n",
        "df['title'] = label_encoder.fit_transform(df['title'])\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df['popularity'] = scaler.fit_transform(df[['popularity']])\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "#Text Vectorization for Reviews\n",
        "\n",
        "df['release_date'] = pd.to_datetime(df['release_date'])\n",
        "df['release_year'] = df['release_date'].dt.year\n",
        "df['release_month'] = df['release_date'].dt.month\n",
        "df['release_day'] = df['release_date'].dt.day\n",
        "df = df.drop(columns=['release_date'])\n",
        "df=df.dropna()\n",
        "\n",
        "max_features = 20000\n",
        "sequence_length = 500\n",
        "\n",
        "vectorize_layer = TextVectorization(\n",
        "    max_tokens=max_features,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=sequence_length\n",
        ")\n",
        "\n",
        "#Adapting the vectorizer to the text data overview\n",
        "vectorize_layer.adapt(df['overview'])\n",
        "\n",
        "X=df.drop(columns=['id','vote_average','vote_count'])\n",
        "y=df['vote_average']\n",
        "X_train,X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "#Building the Model\n",
        "\n",
        "overview_input= Input(shape=(1,),dtype=tf.string, name='overview')\n",
        "popularity_input= Input(shape=(1,), name='popularity')\n",
        "year_input= Input(shape=(1,), name='year')\n",
        "month_input= Input(shape=(1,), name='month')\n",
        "day_input= Input(shape=(1,), name='day')\n",
        "genre_input= Input(shape=(1,), name='genre')\n",
        "language_input= Input(shape=(1,), name='language')\n",
        "title_input= Input(shape=(1,), name='title')\n",
        "\n",
        "#Text processing\n",
        "overview_vector = vectorize_layer(overview_input)\n",
        "overview_embedding = Embedding(max_features, 64)(overview_vector)\n",
        "overview_lstm = LSTM(64)(overview_embedding)\n",
        "\n",
        "#Dense layers for numerical/categorical features\n",
        "popularity_dense = Dense(32, activation=\"relu\")(popularity_input)\n",
        "year_dense= Dense(32, activation=\"relu\")(year_input)\n",
        "month_dense= Dense(32, activation=\"relu\")(month_input)\n",
        "day_dense= Dense(32, activation=\"relu\")(day_input)\n",
        "genre_dense=Dense(32, activation=\"relu\")(genre_input)\n",
        "language_dense= Dense(32, activation=\"relu\")(language_input)\n",
        "title_dense= Dense(32, activation=\"relu\")(title_input)\n",
        "\n",
        "#Concatenate all layers\n",
        "concatenated = Concatenate()([overview_lstm, popularity_dense, year_dense, month_dense, day_dense, genre_dense, language_dense, title_dense])\n",
        "dense_1 = Dense(64, activation='relu')(concatenated)\n",
        "dropout = Dropout(0.5)(dense_1)\n",
        "output = Dense(1)(dropout)\n",
        "\n",
        "#Model\n",
        "model = Model(inputs=[overview_input, popularity_input, year_input, month_input, day_input, genre_input, language_input, title_input], outputs=output)\n",
        "model.compile(optimizer ='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Preparing input data\n",
        "train_overview = X_train['overview'].values\n",
        "train_popularity = X_train['popularity'].values\n",
        "train_year = X_train['release_year'].values\n",
        "train_month = X_train['release_month'].values\n",
        "train_day = X_train['release_day'].values\n",
        "train_genre = X_train['genre'].values\n",
        "train_language = X_train['original_language'].values\n",
        "train_title = X_train['title'].values\n",
        "\n",
        "# Training the Model\n",
        "history = model.fit(\n",
        "    [train_overview, train_popularity, train_year, train_month, train_day, train_genre, train_language, train_title],\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "#preparing test data\n",
        "test_overview = X_test[\"overview\"].values\n",
        "test_popularity = X_test['popularity'].values\n",
        "test_year = X_test['release_year'].values\n",
        "test_month = X_test['release_month'].values\n",
        "test_day = X_test['release_day'].values\n",
        "test_genre = X_test['genre'].values\n",
        "test_language = X_test['original_language'].values\n",
        "test_title = X_test['title'].values\n",
        "\n",
        "# Evaluate the Model\n",
        "model.evaluate([test_overview, test_popularity, test_year, test_month, test_day, test_genre, test_language, test_title], y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "df1722ce-c440-492f-b76f-8f87a2d10538",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df1722ce-c440-492f-b76f-8f87a2d10538",
        "outputId": "8723cb52-d306-48c4-d355-dbfeebde526a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Movie Title: Beethoven's 4th\n"
          ]
        }
      ],
      "source": [
        "\n",
        "encoded_title = 1016\n",
        "original_title = label_encoder.inverse_transform([encoded_title])[0]\n",
        "\n",
        "print(\"Original Movie Title:\", original_title)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22ce2cc4-3524-44af-a3f5-b588d6e58293",
      "metadata": {
        "id": "22ce2cc4-3524-44af-a3f5-b588d6e58293"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}