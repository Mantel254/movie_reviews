{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6adadfa5-2205-4135-a7d4-d7dace0c06a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 265ms/step - loss: 7299.1289 - mae: 44.3002 - val_loss: 5.3885 - val_mae: 1.9502\n",
      "Epoch 2/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 254ms/step - loss: 23.4302 - mae: 3.3307 - val_loss: 2.3704 - val_mae: 1.2312\n",
      "Epoch 3/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 253ms/step - loss: 12.2060 - mae: 2.6671 - val_loss: 2.7724 - val_mae: 1.4521\n",
      "Epoch 4/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 265ms/step - loss: 9.5454 - mae: 2.4414 - val_loss: 2.0820 - val_mae: 1.2376\n",
      "Epoch 5/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 270ms/step - loss: 8.2613 - mae: 2.2983 - val_loss: 2.1298 - val_mae: 1.2674\n",
      "Epoch 6/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 255ms/step - loss: 7.7247 - mae: 2.2187 - val_loss: 1.8493 - val_mae: 1.1666\n",
      "Epoch 7/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 254ms/step - loss: 7.3270 - mae: 2.1782 - val_loss: 1.7834 - val_mae: 1.1462\n",
      "Epoch 8/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 252ms/step - loss: 7.3147 - mae: 2.1959 - val_loss: 1.6735 - val_mae: 1.1010\n",
      "Epoch 9/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 259ms/step - loss: 6.8618 - mae: 2.1095 - val_loss: 1.0063 - val_mae: 0.8189\n",
      "Epoch 10/10\n",
      "\u001b[1m200/200\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 296ms/step - loss: 6.8828 - mae: 2.1213 - val_loss: 0.8818 - val_mae: 0.7619\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 97ms/step - loss: 0.9442 - mae: 0.7957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8992904424667358, 0.7697062492370605]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate, Dropout, LSTM, TextVectorization\n",
    "\n",
    "df=pd.read_csv(\"top10K-TMDB-movies.csv\")\n",
    "\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df,)\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df[\"genre\"] = label_encoder.fit_transform(df['genre'])\n",
    "df['original_language']= label_encoder.fit_transform(df['original_language'])\n",
    "df['title'] = label_encoder.fit_transform(df['title'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df['popularity'] = scaler.fit_transform(df[['popularity']])\n",
    "\n",
    "df = df.dropna()\n",
    "\n",
    "#Text Vectorization for Reviews\n",
    "\n",
    "df['release_date'] = pd.to_datetime(df['release_date'])\n",
    "df['release_year'] = df['release_date'].dt.year\n",
    "df['release_month'] = df['release_date'].dt.month\n",
    "df['release_day'] = df['release_date'].dt.day\n",
    "df = df.drop(columns=['release_date'])\n",
    "df=df.dropna()\n",
    "\n",
    "max_features = 20000\n",
    "sequence_length = 500\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    max_tokens=max_features,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "#Adapting the vectorizer to the text data overview\n",
    "vectorize_layer.adapt(df['overview'])\n",
    "\n",
    "X=df.drop(columns=['id','vote_average','vote_count'])\n",
    "y=df['vote_average']\n",
    "X_train,X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "#Building the Model\n",
    "\n",
    "overview_input= Input(shape=(1,),dtype=tf.string, name='overview')\n",
    "popularity_input= Input(shape=(1,), name='popularity')\n",
    "year_input= Input(shape=(1,), name='year')\n",
    "month_input= Input(shape=(1,), name='month')\n",
    "day_input= Input(shape=(1,), name='day')\n",
    "genre_input= Input(shape=(1,), name='genre')\n",
    "language_input= Input(shape=(1,), name='language')\n",
    "title_input= Input(shape=(1,), name='title')\n",
    "\n",
    "#Text processing\n",
    "overview_vector = vectorize_layer(overview_input)\n",
    "overview_embedding = Embedding(max_features, 64)(overview_vector)\n",
    "overview_lstm = LSTM(64)(overview_embedding)\n",
    "\n",
    "#Dense layers for numerical/categorical features\n",
    "popularity_dense = Dense(32, activation=\"relu\")(popularity_input)\n",
    "year_dense= Dense(32, activation=\"relu\")(year_input)\n",
    "month_dense= Dense(32, activation=\"relu\")(month_input)\n",
    "day_dense= Dense(32, activation=\"relu\")(day_input)\n",
    "genre_dense=Dense(32, activation=\"relu\")(genre_input)\n",
    "language_dense= Dense(32, activation=\"relu\")(language_input)\n",
    "title_dense= Dense(32, activation=\"relu\")(title_input)\n",
    "\n",
    "#Concatenate all layers\n",
    "concatenated = Concatenate()([overview_lstm, popularity_dense, year_dense, month_dense, day_dense, genre_dense, language_dense, title_dense])\n",
    "dense_1 = Dense(64, activation='relu')(concatenated)\n",
    "dropout = Dropout(0.5)(dense_1)\n",
    "output = Dense(1)(dropout)\n",
    "\n",
    "#Model\n",
    "model = Model(inputs=[overview_input, popularity_input, year_input, month_input, day_input, genre_input, language_input, title_input], outputs=output)\n",
    "model.compile(optimizer ='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Prepare input data\n",
    "train_overview = X_train['overview'].values\n",
    "train_popularity = X_train['popularity'].values\n",
    "train_year = X_train['release_year'].values\n",
    "train_month = X_train['release_month'].values\n",
    "train_day = X_train['release_day'].values\n",
    "train_genre = X_train['genre'].values\n",
    "train_language = X_train['original_language'].values\n",
    "train_title = X_train['title'].values\n",
    "\n",
    "# Train the Model\n",
    "history = model.fit(\n",
    "    [train_overview, train_popularity, train_year, train_month, train_day, train_genre, train_language, train_title],\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "#prepare test data\n",
    "test_overview = X_test[\"overview\"].values\n",
    "test_popularity = X_test['popularity'].values\n",
    "test_year = X_test['release_year'].values\n",
    "test_month = X_test['release_month'].values\n",
    "test_day = X_test['release_day'].values\n",
    "test_genre = X_test['genre'].values\n",
    "test_language = X_test['original_language'].values\n",
    "test_title = X_test['title'].values\n",
    "\n",
    "# Evaluate the Model\n",
    "model.evaluate([test_overview, test_popularity, test_year, test_month, test_day, test_genre, test_language, test_title], y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df1722ce-c440-492f-b76f-8f87a2d10538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Assuming you have already fitted the LabelEncoder to the movie titles\\n# and stored it in the variable label_encoder_title\\n\\n# Suppose you have an encoded movie title\\nencoded_title = 1016  # Replace 123 with the actual encoded title\\n\\n# Use inverse_transform to get the original movie title\\noriginal_title = label_encoder_title.inverse_transform([encoded_title])[0]\\n\\nprint(\"Original Movie Title:\", original_title)\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Assuming you have already fitted the LabelEncoder to the movie titles\n",
    "# and stored it in the variable label_encoder_title\n",
    "\n",
    "# Suppose you have an encoded movie title\n",
    "encoded_title = 1016  # Replace 123 with the actual encoded title\n",
    "\n",
    "# Use inverse_transform to get the original movie title\n",
    "original_title = label_encoder_title.inverse_transform([encoded_title])[0]\n",
    "\n",
    "print(\"Original Movie Title:\", original_title)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ce2cc4-3524-44af-a3f5-b588d6e58293",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
